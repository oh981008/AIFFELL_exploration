{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn 라이브러리를 활용한 모델 예측(22.11.01)\n",
    "## 작성자 : 오순정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프로젝트 (1) load_digits : 손글씨를 분류해 봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 선언\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "# (2) 데이터 준비 /load_digit 준비\n",
    "#digit 데이터 전체 불러옴\n",
    "digit=load_digits()\n",
    "print(digit.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.] (1797, 64)\n"
     ]
    }
   ],
   "source": [
    "# (3)-1 Feature Data 지정하기\n",
    "#데이터 색 분포\n",
    "feature_data=digit.data\n",
    "#피처 데이터 값 -> 8,8 이미지 , 1797 데이터 갯수\n",
    "print(feature_data[0],feature_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAADyUlEQVR4nO3dUVFjaRRG0T9TYyAWggSwkkgACSABL5FAJBALSCAS7higeZo6vZte6zF5+KiEXbeKB85u27YF9Pzzu38A4GvihChxQpQ4IUqcEPXvd2/udrsf+afc4/E4uvf6+jq2dblcxrZeXl7Gtm6329jWtG3bdl+97skJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqG/PMfxUk+cR1lrrcDiMbe33+7Gtz8/Psa3T6TS2tdZa5/N5dO8rnpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IypxjuL+/H9uaPI+w1lp3d3djWx8fH2Nbb29vY1uTvx9rOccAfEOcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiMrcStnv92Nb1+t1bGut2fslk6Y/x7+NJydEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROi/spzDJfLZWzrJ5v8zm6329hWhScnRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTojLnGCb/3f79/f3Y1rTJEwmTn+P5fB7bqvDkhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtRu27Zfv7nb/frN/9nhcJiaWu/v72Nba6319PQ0tnU8Hse2Jr+zh4eHsa1p27btvnrdkxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSozK2USY+Pj6N7z8/PY1vX63Vs63Q6jW39ZG6lwB9GnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBD17TkG4Pfx5IQocUKUOCFKnBAlTogSJ0T9ByioUst9Wxj9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#이미지 데이터 보기\n",
    "plt.imshow(digit.data[0].reshape(8, 8), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 8 9 8] (1797,)\n"
     ]
    }
   ],
   "source": [
    "# (3)-2 Label Data 지정하기\n",
    "#숫자 데이터 : 정답지 0,1,2,3,4,5,6,7,8,9 구분\n",
    "label_data=digit.target\n",
    "print(label_data,label_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# (3)-3 Target Names 출력해 보기\n",
    "print(digit.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0        0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1        0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2        0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3        0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4        0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "\n",
       "   pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       "0        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
       "3        0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "\n",
       "   pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       "0        0.0        0.0        6.0       13.0       10.0        0.0   \n",
       "1        0.0        0.0        0.0       11.0       16.0       10.0   \n",
       "2        0.0        0.0        0.0        3.0       11.0       16.0   \n",
       "3        0.0        0.0        7.0       13.0       13.0        9.0   \n",
       "4        0.0        0.0        0.0        2.0       16.0        4.0   \n",
       "\n",
       "   pixel_7_6  pixel_7_7  \n",
       "0        0.0        0.0  \n",
       "1        0.0        0.0  \n",
       "2        9.0        0.0  \n",
       "3        0.0        0.0  \n",
       "4        0.0        0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3)-4 데이터 Describe 해 보기\n",
    "digit_dataframe = pd.DataFrame(data=digit.data, columns=digit.feature_names)\n",
    "digit_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "print(digit.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수:  1437 , X_test 개수:  360\n",
      "y_train 개수:  1437 , y_test 개수:  360\n"
     ]
    }
   ],
   "source": [
    "# (4) train, test 데이터 분리\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature_data, \n",
    "                                                    label_data, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=8)\n",
    "\n",
    "\n",
    "\n",
    "print('X_train 개수: ', len(x_train),', X_test 개수: ', len(x_test))\n",
    "print('y_train 개수: ', len(y_train),', y_test 개수: ', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93        34\n",
      "           1       0.79      0.84      0.82        37\n",
      "           2       0.84      0.84      0.84        32\n",
      "           3       0.86      0.82      0.84        38\n",
      "           4       0.88      0.88      0.88        26\n",
      "           5       0.86      0.88      0.87        49\n",
      "           6       0.94      0.86      0.90        37\n",
      "           7       0.93      0.95      0.94        40\n",
      "           8       0.69      0.76      0.72        33\n",
      "           9       0.85      0.82      0.84        34\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.86       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (5) 다양한 모델로 학습시키기\n",
    "# (5)-1 Decision Tree 사용해 보기\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32) \n",
    "decision_tree.fit(x_train, y_train)\n",
    "y_pred_1 = decision_tree.predict(x_test)\n",
    "accuracy_1 = accuracy_score(y_test, y_pred_1) # y_pred(답안지)를 y_test(정답지)로 채점\n",
    "\n",
    "print(classification_report(y_test, y_pred_1)) # 결과 지표를 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        34\n",
      "           1       0.95      1.00      0.97        37\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       1.00      0.92      0.96        38\n",
      "           4       1.00      0.88      0.94        26\n",
      "           5       0.96      0.98      0.97        49\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       0.95      1.00      0.98        40\n",
      "           8       0.97      0.94      0.95        33\n",
      "           9       0.92      0.97      0.94        34\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (5)-2 Random Forest 사용해 보기\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(x_train, y_train) \n",
    "y_pred_2 = random_forest.predict(x_test) \n",
    "accuracy_2 = accuracy_score(y_test, y_pred_2) # y_pred(답안지)를 y_test(정답지)로 채점\n",
    "print(classification_report(y_test, y_pred_2)) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        34\n",
      "           1       0.93      1.00      0.96        37\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       1.00      0.97      0.99        38\n",
      "           4       1.00      0.96      0.98        26\n",
      "           5       0.96      0.98      0.97        49\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       1.00      1.00      1.00        40\n",
      "           8       0.97      0.91      0.94        33\n",
      "           9       0.97      0.97      0.97        34\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (5)-3  SVM 사용해 보기\n",
    "from sklearn import svm \n",
    "svm_model = svm.SVC() \n",
    "\n",
    "svm_model.fit(x_train, y_train) \n",
    "y_pred_3 = svm_model.predict(x_test)\n",
    "accuracy_3 = accuracy_score(y_test, y_pred_3) # y_pred(답안지)를 y_test(정답지)로 채점\n",
    "print(classification_report(y_test, y_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        34\n",
      "           1       0.91      0.86      0.89        37\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       0.95      0.95      0.95        38\n",
      "           4       1.00      0.96      0.98        26\n",
      "           5       0.96      0.92      0.94        49\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       1.00      0.95      0.97        40\n",
      "           8       0.83      0.91      0.87        33\n",
      "           9       0.87      0.97      0.92        34\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (5)-4  SGD Classifier 사용해 보기\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "sgd_model = SGDClassifier() \n",
    "\n",
    "sgd_model.fit(x_train, y_train) # 분류기에 x와 y의 훈련 데이터를 넣어 훈련 시킨다.\n",
    "y_pred_4 = sgd_model.predict(x_test)\n",
    "accuracy_4 = accuracy_score(y_test, y_pred_4) # y_pred(답안지)를 y_test(정답지)로 채점\n",
    "\n",
    "print(classification_report(y_test, y_pred_4)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        34\n",
      "           1       0.90      0.97      0.94        37\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       1.00      0.95      0.97        38\n",
      "           4       1.00      0.96      0.98        26\n",
      "           5       0.96      0.96      0.96        49\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       1.00      1.00      1.00        40\n",
      "           8       0.88      0.88      0.88        33\n",
      "           9       0.91      0.91      0.91        34\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (5)-5  Logistic Regression 사용해 보기\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "logistic_model = LogisticRegression(max_iter=3000) \n",
    "\n",
    "logistic_model.fit(x_train, y_train)\n",
    "y_pred_5 = logistic_model.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dicisiontree': 0.8583333333333333,\n",
       " 'random': 0.9722222222222222,\n",
       " 'svm': 0.9805555555555555,\n",
       " 'sgd': 0.95,\n",
       " 'logisitic': 0.9638888888888889}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도 비교 \n",
    "accuracy_5 = accuracy_score(y_test, y_pred_5) # y_pred(답안지)를 y_test(정답지)로 채점\n",
    "accuracy={'dicisiontree':accuracy_1,'random':accuracy_2,'svm':accuracy_3,'sgd':accuracy_4,'logisitic':accuracy_5}\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회고\n",
    "학습 관련 변수들을 작성하면서 처음에는 그냥 label_data, feature_data로 알아보기 쉽게 1차원적으로 변수명을 적었다. 코드를 작성하다 아차 싶었다. 어떤 데이터에 종속되는지에 대한 설명 없이 label_data, feature_data 로만 작성하다 보니 다른 인공지능 학습할 때 변수가 중복될 가능성이 높았다. 그래서 괜히 아이펠에서 digit_label. digit_data로 적은 게 아니구나 싶으면서 변수명 선정 시 데이터 소속을 명확히 밝히면서 어떤 목적을 갖고 있는지 명시해야함을 느꼈다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 로지스틱 회귀 분류 실패\n",
    "<에러>ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "수렴 경고: lbfgs가 수렴하지 못했습니다(상태=1):\n",
    "중지: 총 반복 횟수가 한계에 도달했습니다.\n",
    "\n",
    "로지스틱 분류가 안되서 경덕님께 여쭤보니 경덕님이 해답을 주셨습니다.!! 말씀하시길 반복횟수가 적어서 문제가 발생한거라고 말씀주셔서 max_iter 변수로 100에서 3000으로 변경하니 문제가 해결되었습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델 적합도 \n",
    "svm > randomforest > logisitic>sgd > decisiontree\n",
    "선형 벡터 머신 모델이 제일 정확도가 높게 나왔으므로 svm 모델이 적합하다.\n",
    "\n",
    "그런데 왜 적합한지에 대해 서술을 하고 싶은데 서술을 못하겠다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## 프로젝트 (2) load_wine : 와인을 분류해 봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#라이브러리 임포트 \n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])\n"
     ]
    }
   ],
   "source": [
    "# (2) 데이터 준비 \n",
    "wine=load_wine()\n",
    "print(wine.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 살펴보니 feature_data 목록으로 alchol, malic acid, ash 등 와인 감별에 필요한 목록이 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "        1.065e+03],\n",
       "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "        1.185e+03],\n",
       "       ...,\n",
       "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "        8.350e+02],\n",
       "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "        8.400e+02],\n",
       "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "        5.600e+02]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3) 데이터 이해하기\n",
    "# (3)-1 feature data 지정하기\n",
    "wine_data=wine.data\n",
    "wine_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  target  \n",
       "0                            3.92   1065.0     0.0  \n",
       "1                            3.40   1050.0     0.0  \n",
       "2                            3.17   1185.0     0.0  \n",
       "3                            3.45   1480.0     0.0  \n",
       "4                            2.93    735.0     0.0  \n",
       "..                            ...      ...     ...  \n",
       "173                          1.74    740.0     2.0  \n",
       "174                          1.56    750.0     2.0  \n",
       "175                          1.56    835.0     2.0  \n",
       "176                          1.62    840.0     2.0  \n",
       "177                          1.60    560.0     2.0  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data = pd.DataFrame(data= np.c_[wine['data'], wine['target']],\n",
    "                     columns= wine['feature_names']+ ['target'])\n",
    "\n",
    "wine_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "민석님과 함께 feature data를 실제로 표로 확인을 하니 칼럼 목록 데이터들이 십진수로 표현됨을 함께 확인했습니다 ㅋㄷ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3)-2 label Data 지정하기\n",
    "\n",
    "#와인 클래스 0,1,2 중 나눠져있음\n",
    "wine_label=wine.target\n",
    "wine_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3-)3 target Names 출력해 보기\n",
    "wine.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3)-4 데이터 Describe 해 보기\n",
    "wine_dataframe = pd.DataFrame(data=wine_data, columns=wine.feature_names)\n",
    "wine_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train 개수:  142 , X_test 개수:  36\n",
      "y_train 개수:  142 , y_test 개수:  36\n"
     ]
    }
   ],
   "source": [
    "# (4) train, test 데이터 분리\n",
    "x_train, x_test, y_train, y_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=8)\n",
    "\n",
    "\n",
    "\n",
    "print('x_train 개수: ', len(x_train),', X_test 개수: ', len(x_test))\n",
    "print('y_train 개수: ', len(y_train),', y_test 개수: ', len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (5) 다양한 모델로 학습시키기\n",
    "# (5)-1 Decision Tree 사용해 보기\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32) \n",
    "decision_tree.fit(x_train, y_train)\n",
    "y_pred_6 = decision_tree.predict(x_test)\n",
    "accuracy_6 = accuracy_score(y_test, y_pred_6)\n",
    "\n",
    "print(classification_report(y_test, y_pred_6)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (5)-2 Random Forest 사용해 보기\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(x_train, y_train) \n",
    "y_pred_7 = random_forest.predict(x_test) \n",
    "accuracy_7 = accuracy_score(y_test, y_pred_7)\n",
    "\n",
    "print(classification_report(y_test, y_pred_7)) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82        11\n",
      "           1       0.56      1.00      0.72        14\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.64        36\n",
      "   macro avg       0.46      0.61      0.51        36\n",
      "weighted avg       0.47      0.64      0.53        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (5)-3  SVM 사용해 보기\n",
    "from sklearn import svm \n",
    "svm_model = svm.SVC() \n",
    "\n",
    "svm_model.fit(x_train, y_train) \n",
    "y_pred_8 = svm_model.predict(x_test)\n",
    "accuracy_8 = accuracy_score(y_test, y_pred_8)\n",
    "\n",
    "print(classification_report(y_test, y_pred_8, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.73      0.80        11\n",
      "           1       0.52      1.00      0.68        14\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.47      0.58      0.49        36\n",
      "weighted avg       0.47      0.61      0.51        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (5)-4  SGD Classifier 사용해 보기\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "sgd_model = SGDClassifier() \n",
    "\n",
    "sgd_model.fit(x_train, y_train) # 분류기에 x와 y의 훈련 데이터를 넣어 훈련 시킨다.\n",
    "y_pred_9 = sgd_model.predict(x_test)\n",
    "accuracy_9 = accuracy_score(y_test, y_pred_9)\n",
    "\n",
    "print(classification_report(y_test, y_pred_9,zero_division=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        11\n",
      "           1       0.82      1.00      0.90        14\n",
      "           2       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.94      0.91      0.92        36\n",
      "weighted avg       0.93      0.92      0.92        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (5)-5  Logistic Regression 사용해 보기\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "logistic_model = LogisticRegression(max_iter=3000) \n",
    "\n",
    "logistic_model.fit(x_train, y_train)\n",
    "y_pred_10 = logistic_model.predict(x_test)\n",
    "accuracy_10 = accuracy_score(y_test, y_pred_10)\n",
    "\n",
    "print(classification_report(y_test, y_pred_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dicisiontree': 1.0,\n",
       " 'random': 1.0,\n",
       " 'svm': 0.6388888888888888,\n",
       " 'sgd': 0.6111111111111112,\n",
       " 'logisitic': 0.9166666666666666}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도 비교 \n",
    "accuracy={'dicisiontree':accuracy_6,'random':accuracy_7,'svm':accuracy_8,'sgd':accuracy_9,'logisitic':accuracy_10}\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회고\n",
    "\n",
    "##### 에러\n",
    "SVM 모델과 SGD 모델에 zero_division error가 발생하였다.\n",
    "\n",
    "print(classification_report(y_test, y_pred_9)) 문장에 print(classification_report(y_test, y_pred_9,zero_division=0))에 zero_division error 매개변수를 0으로 추가하여 최소한의 경고를 제한할 수 있다.\n",
    "\n",
    "https://stackoverflow.com/questions/62326735/metrics-f1-warning-zero-division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델 정확도\n",
    "랜덤 포레스트 모델에과 의견결정나무 모델에서 100% 가 나왔다 \n",
    "정확도 비교하면 \n",
    "랜덤 포레스트 모델 = 의견결정나무 모델 > 로지스틱 > 선형 이진 분류 > 확률 경사 \n",
    "\n",
    "아무래도 위 표에서 확인했다시피 alchol,malic_acid\tash\talcalinity_of_ash .. 등 피처 요소들이 다양했다.\n",
    "의견결정나무 모델이 분류하는 문제에서 대표적으로 사용되는 모델이라 그런지 100% 인데, 여기서 더 확장시킨 랜덤 포레스트 모델이 더욱 다양한 요소들을 고려할 수 있어 100% 정확도를 보인 듯 하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-13. 프로젝트 (3) load_breast_cancer : 유방암 여부를 진단해 봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#라이브러리 임포트 \n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "# (2) 데이터 준비 \n",
    "cancer=load_breast_cancer()\n",
    "print(cancer.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3) 데이터 이해하기\n",
    "# (3)-1 feature data 지정하기\n",
    "cancer_data=cancer.data\n",
    "cancer_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 종양 크기에 따른 악성, 양성인지 판단, 정답지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3)-2 label Data 지정하기\n",
    "cancer_label=cancer.target\n",
    "cancer_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 악성, 양성 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3-)3 target Names 출력해 보기\n",
    "cancer.target_names\n",
    "#악성, 양성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 종양 크기에 대한 상세한 정보를 적은 걸 볼 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3)-4 데이터 Describe 해 보기\n",
    "cancer_dataframe = pd.DataFrame(data=cancer_data, columns=cancer.feature_names)\n",
    "cancer_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train 개수:  455 , X_test 개수:  114\n",
      "y_train 개수:  455 , y_test 개수:  114\n"
     ]
    }
   ],
   "source": [
    "# (4) train, test 데이터 분리\n",
    "x_train, x_test, y_train, y_test = train_test_split(cancer_data, \n",
    "                                                    cancer_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=8)\n",
    "\n",
    "\n",
    "\n",
    "print('x_train 개수: ', len(x_train),', X_test 개수: ', len(x_test))\n",
    "print('y_train 개수: ', len(y_train),', y_test 개수: ', len(y_test))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 학습시키기 전에 .. \n",
    "암 진단의 경우 오차 행렬이 필요하다. 양성인데 음성이라 판단할 확률이라던가, 음성인데 양성으로 판단할 확률이라던가,,\n",
    "정확도만으로 모든 것을 판단할 수 없으므로 암 진단에 있어 양성인데 음성일 확률이 있으면 안돼므로 recall 값을 고려해야한다.\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "print(recall_acore(y_test, pred))\n",
    "\n",
    "https://kylo8.tistory.com/entry/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%98%A4%EC%B0%A8%ED%96%89%EB%A0%AC-%EC%A0%95%ED%99%95%EB%8F%84-%EC%A0%95%EB%B0%80%EB%8F%84%EC%9E%AC%ED%98%84%EC%9C%A8\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "출처: https://driip.me/3ef36050-f5a3-41ea-9f23-874afe665342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92        46\n",
      "           1       0.93      0.97      0.95        68\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "0.9705882352941176\n"
     ]
    }
   ],
   "source": [
    "# # (5) 다양한 모델로 학습시키기\n",
    "# (5)-1 Decision Tree 사용해 보기\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32) \n",
    "decision_tree.fit(x_train, y_train)\n",
    "y_pred_11 = decision_tree.predict(x_test)\n",
    "accuracy_11 = accuracy_score(y_test, y_pred_11)\n",
    "\n",
    "#리콜 구하기, 라이브러리 함수 호출로 가능\n",
    "from sklearn.metrics import recall_score \n",
    "recall_score_11=recall_score(y_test, y_pred_11)\n",
    "\n",
    "print(classification_report(y_test, y_pred_11)) \n",
    "print(recall_score_11) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        46\n",
      "           1       0.97      1.00      0.99        68\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (5)-2 Random Forest 사용해 보기\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(x_train, y_train) \n",
    "y_pred_12 = random_forest.predict(x_test) \n",
    "accuracy_12 = accuracy_score(y_test, y_pred_12)\n",
    "\n",
    "from sklearn.metrics import recall_score \n",
    "recall_score_12=recall_score(y_test, y_pred_12)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred_12)) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92        46\n",
      "           1       0.92      0.99      0.95        68\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (5)-3  SVM 사용해 보기\n",
    "from sklearn import svm \n",
    "svm_model = svm.SVC() \n",
    "\n",
    "svm_model.fit(x_train, y_train) \n",
    "y_pred_13 = svm_model.predict(x_test)\n",
    "accuracy_13 = accuracy_score(y_test, y_pred_13)\n",
    "\n",
    "from sklearn.metrics import recall_score \n",
    "recall_score_13=recall_score(y_test, y_pred_13)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred_13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.78      0.87        46\n",
      "           1       0.87      0.99      0.92        68\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.92      0.88      0.90       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (5)-4  SGD Classifier 사용해 보기\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "sgd_model = SGDClassifier() \n",
    "\n",
    "sgd_model.fit(x_train, y_train) # 분류기에 x와 y의 훈련 데이터를 넣어 훈련 시킨다.\n",
    "y_pred_14 = sgd_model.predict(x_test)\n",
    "accuracy_14 = accuracy_score(y_test, y_pred_14)\n",
    "\n",
    "\n",
    "from sklearn.metrics import recall_score \n",
    "recall_score_14=recall_score(y_test, y_pred_14)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred_14)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        46\n",
      "           1       0.97      0.97      0.97        68\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.96      0.96       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #(5)-5  Logistic Regression 사용해 보기\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "logistic_model = LogisticRegression(max_iter=3000) \n",
    "\n",
    "logistic_model.fit(x_train, y_train)\n",
    "y_pred_15 = logistic_model.predict(x_test)\n",
    "accuracy_15 = accuracy_score(y_test, y_pred_15)\n",
    "\n",
    "from sklearn.metrics import recall_score \n",
    "recall_score_15=recall_score(y_test, y_pred_15)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred_15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dicisiontree': 0.9385964912280702,\n",
       " 'random': 0.9824561403508771,\n",
       " 'svm': 0.9385964912280702,\n",
       " 'sgd': 0.9035087719298246,\n",
       " 'logisitic': 0.9649122807017544}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도 비교 \n",
    "accuracy={'dicisiontree':accuracy_11,'random':accuracy_12,'svm':accuracy_13,'sgd':accuracy_14,'logisitic':accuracy_15}\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dicisiontree': 0.9705882352941176,\n",
       " 'random': 1.0,\n",
       " 'svm': 0.9852941176470589,\n",
       " 'sgd': 0.9852941176470589,\n",
       " 'logisitic': 0.9705882352941176}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리콜 비교 \n",
    "accuracy={'dicisiontree':recall_score_11,'random':recall_score_12,'svm':recall_score_13,'sgd':recall_score_14,'logisitic':recall_score_15}\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회고\n",
    "\n",
    "높은 리콜 기준으로 랜덤> sgd=svm >의견결정나무=로지스틱  순으로 나왔다.\n",
    "\n",
    "리콜이 100%일 경우 실제 양성일 경우 모두 양성으로 예측한다는 뜻이다. 98%도 높은걸로 보이지만 100명중에 2명을 오진을 한다는 뜻이여서,, 신중해야하는 판별인 만큼 100% 예측 가능한 랜덤 포레스트 모델이 제일 성능이 좋다고 할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
